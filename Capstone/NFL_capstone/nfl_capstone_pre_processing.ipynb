{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.3 64-bit ('Springboard': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c89e3a547b31aeddc31efee464a9a300846520c3802d37af32d3efdc899ae2c5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Capstone: Pre-processing and Training Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "source": [
    "## Import of csv's created in nfl_capstone_EDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = pd.read_csv('teamstarterdraft.csv')\n",
    "yearAV = pd.read_csv('teamstarterdraftAV.csv')\n",
    "week = pd.read_csv('weekstarterdraft.csv')\n",
    "weekAV = pd.read_csv('weekstarterdraftAV.csv')"
   ]
  },
  {
   "source": [
    "### Creation of 2 additional dataframes that do not include the categorical variables of coach, offcoor, defcoor, off scheme, and def align.  If these do not add much to the variance, they are just preventing tree based algorithms from functioning well, as the number of dummy columns is large"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearnocoach = year.drop(columns=['coach', 'offcoor', 'defcoor', 'offscheme', 'defalign'])\n",
    "yearnocoachAV = yearAV.drop(columns=['coach', 'offcoor', 'defcoor', 'offscheme', 'defalign'])"
   ]
  },
  {
   "source": [
    "## Create pipeline for Regression analysis"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "year_X = year.drop('DraftTeamSelection', axis=1)\n",
    "year_y = year['DraftTeamSelection']\n",
    "\n",
    "yearAV_X = yearAV.drop('DraftTeamSelection', axis=1)\n",
    "yearAV_y = yearAV['DraftTeamSelection']\n",
    "\n",
    "week_X = week.drop('DraftTeamSelection', axis=1)\n",
    "week_y = week['DraftTeamSelection']\n",
    "\n",
    "weekAV_X = weekAV.drop('DraftTeamSelection', axis=1)\n",
    "weekAV_y = weekAV['DraftTeamSelection']\n",
    "\n",
    "categorical_features = list(year.select_dtypes(include=['category', object]).columns)\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "numeric_features = list(year.select_dtypes(include=['int', 'float']).columns)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "year_X_train, year_X_test, year_y_train, year_y_test = train_test_split(year_X, year_y, test_size=0.33, random_state=42)\n",
    "\n",
    "yearAV_X_train, yearAV_X_test, yearAV_y_train, yearAV_y_test = train_test_split(yearAV_X, yearAV_y, test_size=0.33, random_state=42)\n",
    "\n",
    "week_X_train, week_X_test, week_y_train, week_y_test = train_test_split(week_X, week_y, test_size=0.33, random_state=42)\n",
    "\n",
    "weekAV_X_train, weekAV_X_test, weekAV_y_train, weekAV_y_test = train_test_split(weekAV_X, weekAV_y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('num',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean...\n",
       "                                                   'StartingPlayerGSRB',\n",
       "                                                   'StartingPlayerGSTE', ...]),\n",
       "                                                 ('cat',\n",
       "                                                  OneHotEncoder(categories='auto',\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='ignore',\n",
       "                                                                sparse=True),\n",
       "                                                  ['Team', 'coach', 'offcoor',\n",
       "                                                   'defcoor', 'offscheme',\n",
       "                                                   'defalign',\n",
       "                                                   'DraftPosition'])],\n",
       "                                   verbose=False)),\n",
       "                ('classifier',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "clf.fit(year_X_train, year_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model score: -0.146\n"
     ]
    }
   ],
   "source": [
    "clf.predict(year_X_test)\n",
    "print(\"model score: %.3f\" % clf.score(year_X_test, year_y_test))"
   ]
  }
 ]
}