{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.3 64-bit ('Springboard': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c89e3a547b31aeddc31efee464a9a300846520c3802d37af32d3efdc899ae2c5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# NFL Capstone:Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Starting Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "source": [
    "## Import datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = pd.read_csv('../data/teamstarterdraft.csv')\n",
    "yearAV = pd.read_csv('../data/teamstarterdraftAV.csv')\n",
    "week = pd.read_csv('../data/weekstarterdraft.csv')\n",
    "weekAV = pd.read_csv('../data/weekstarterdraftAV.csv')\n",
    "yearnocoach = year.drop(columns=['coach', 'offcoor', 'defcoor', 'offscheme', 'defalign'])\n",
    "yearnocoachAV = yearAV.drop(columns=['coach', 'offcoor', 'defcoor', 'offscheme', 'defalign'])"
   ]
  },
  {
   "source": [
    "## New Datasets with bucketization of major categorical variables and ordinal encoding of weeks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekord = week.copy()\n",
    "weekAVord = weekAV.copy()\n",
    "weekord['Week'] = weekord['Week'].replace('Wild Card', 18)\n",
    "weekord['Week'] = weekord['Week'].replace('Division', 19)\n",
    "weekord['Week'] = weekord['Week'].replace('Conf. Champ.', 20)\n",
    "weekord['Week'] = weekord['Week'].replace('SuperBowl', 21)\n",
    "\n",
    "weekAVord['Week'] = weekAVord['Week'].replace('Wild Card', 18)\n",
    "weekAVord['Week'] = weekAVord['Week'].replace('Division', 19)\n",
    "weekAVord['Week'] = weekAVord['Week'].replace('Conf. Champ.', 20)\n",
    "weekAVord['Week'] = weekAVord['Week'].replace('SuperBowl', 21)\n",
    "\n",
    "weekord['Week']= weekord['Week'].astype(int)\n",
    "weekAVord['Week']= weekAVord['Week'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearbucket = year.copy()\n",
    "yearAVbucket = yearAV.copy()\n",
    "top = yearbucket['coach'].isin(yearbucket['coach'].value_counts().index[:61])\n",
    "yearbucket.loc[~top, 'coach'] = 'other'\n",
    "\n",
    "top = yearbucket['offcoor'].isin(yearbucket['offcoor'].value_counts().index[:61])\n",
    "yearbucket.loc[~top, 'offcoor'] = 'other'\n",
    "\n",
    "top = yearbucket['defcoor'].isin(yearbucket['defcoor'].value_counts().index[:61])\n",
    "yearAVbucket.loc[~top, 'defcoor'] = 'other'\n",
    "\n",
    "top = yearAVbucket['coach'].isin(yearAVbucket['coach'].value_counts().index[:61])\n",
    "yearAVbucket.loc[~top, 'coach'] = 'other'\n",
    "\n",
    "top = yearAVbucket['offcoor'].isin(yearAVbucket['offcoor'].value_counts().index[:61])\n",
    "yearAVbucket.loc[~top, 'offcoor'] = 'other'\n",
    "\n",
    "top = yearAVbucket['defcoor'].isin(yearAVbucket['defcoor'].value_counts().index[:61])\n",
    "yearAVbucket.loc[~top, 'defcoor'] = 'other'"
   ]
  },
  {
   "source": [
    "# Model Selection Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                     R2       MSE      RMSE       MAE  \\\nyear          -0.003689  7.030284  2.651468  2.206876   \nyearAV        -0.001526  6.826498  2.612757  2.168102   \nweek           0.027613  6.739145  2.595986  2.170780   \nweekAV         0.034467  6.500216  2.549552  2.140941   \nyearnocoach    0.015172  6.595608  2.568192  2.152198   \nyearnocoachAV  0.007238  6.919831  2.630557  2.194490   \n\n                                                  best regressor  \nyear           Lasso(alpha=0.0029470517025518097, copy_X=True...  \nyearAV         Lasso(alpha=0.004291934260128779, copy_X=True,...  \nweek           Lasso(alpha=0.0013894954943731374, copy_X=True...  \nweekAV         Lasso(alpha=0.0011513953993264468, copy_X=True...  \nyearnocoach    Ridge(alpha=1.0, copy_X=True, fit_intercept=Tr...  \nyearnocoachAV  Ridge(alpha=1.0, copy_X=True, fit_intercept=Tr...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "dfdict = {'year':year, 'yearAV':yearAV, 'week':week,'weekAV':weekAV, 'yearnocoach': yearnocoach,                        'yearnocoachAV':yearnocoachAV}\n",
    "\n",
    "\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftTeamSelection', axis=1)\n",
    "        y = df['DraftTeamSelection']\n",
    "        \n",
    "        categorical_features = list(X.select_dtypes(include=['category', object]).columns)\n",
    "        categorical_transformer = OneHotEncoder(sparse=True, handle_unknown='ignore')\n",
    "\n",
    "        numeric_features = list(X.select_dtypes(include=['int', 'float']).columns)\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('num', numeric_transformer, numeric_features),\n",
    "                ('cat', categorical_transformer, categorical_features)])\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('regressor', LinearRegression())])\n",
    "        search_space = [{'regressor': [LinearRegression()],\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor':[Ridge()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [Lasso()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [ElasticNet()],\n",
    "                        'regressor__l1_ratio': np.linspace(0,1,30),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [RandomForestRegressor()],\n",
    "                        'regressor__n_estimators': np.logspace(2,3,20),\n",
    "                        'regressor__max_depth': np.linspace(1,10,10),\n",
    "                        'regressor__criterion': ['mse', 'mae']}]\n",
    "        \n",
    "        reg_CV = GridSearchCV(reg, search_space, cv=5, n_jobs=-1)\n",
    "        best_model = reg_CV.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        df_best_regressor = best_model.best_estimator_.get_params()['regressor']\n",
    "        R2 = r2_score(y_test, y_pred)\n",
    "        MSE = mean_squared_error(y_test, y_pred)\n",
    "        RMSE = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        MAE = mean_absolute_error(y_test, y_pred)\n",
    "        results = pd.DataFrame({\"R2\": R2, 'MSE':MSE, 'RMSE': RMSE, 'MAE':MAE, 'best regressor':                 df_best_regressor}, index=[key])\n",
    "        dfresults = dfresults.append(results)\n",
    "print(dfresults)"
   ]
  },
  {
   "source": [
    "                     R2       MSE      RMSE       MAE  \\\n",
    "year           0.006471  7.053925  2.655923  2.210044   \n",
    "yearAV         0.001267  6.893871  2.625618  2.224999   \n",
    "week           0.027048  6.687490  2.586018  2.160993   \n",
    "weekAV         0.038889  6.670500  2.582731  2.162373   \n",
    "yearnocoach    0.008149  6.860356  2.619228  2.175273   \n",
    "yearnocoachAV  0.000010  6.733512  2.594901  2.177637   \n",
    "\n",
    "                                                  best regressor  \n",
    "year           Lasso(alpha=0.033932217718953266, copy_X=True,...  \n",
    "yearAV         Lasso(alpha=0.0029470517025518097, copy_X=True...  \n",
    "week           Lasso(alpha=0.0011513953993264468, copy_X=True...  \n",
    "weekAV         Lasso(alpha=0.0011513953993264468, copy_X=True...  \n",
    "yearnocoach    Ridge(alpha=1.0, copy_X=True, fit_intercept=Tr...  \n",
    "yearnocoachAV  Lasso(alpha=0.0020235896477251557, copy_X=True...  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Regression Model Selection with new Datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    R2       MSE      RMSE       MAE  \\\nyearbucket    0.002520  7.142888  2.672618  2.240276   \nyearAVbucket  0.013071  6.455497  2.540767  2.151045   \nweek          0.024096  6.787724  2.605326  2.179035   \nweekAV        0.041493  6.602885  2.569608  2.149873   \n\n                                                 best regressor  \nyearbucket    Lasso(alpha=0.0016768329368110067, copy_X=True...  \nyearAVbucket  Lasso(alpha=0.0020235896477251557, copy_X=True...  \nweek          Ridge(alpha=0.04941713361323833, copy_X=True, ...  \nweekAV        Ridge(alpha=0.040949150623804234, copy_X=True,...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#this is what I changed from cell above\n",
    "dfdict = {'yearbucket':yearbucket, 'yearAVbucket':yearAVbucket, 'week':weekord,'weekAV':weekAVord}\n",
    "\n",
    "\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftTeamSelection', axis=1)\n",
    "        y = df['DraftTeamSelection']\n",
    "        categorical_features = list(df.select_dtypes(include=['category', object]).columns)\n",
    "        categorical_transformer = OneHotEncoder(sparse=True, handle_unknown='ignore')\n",
    "\n",
    "        numeric_features = list(df.select_dtypes(include=['int', 'float']).columns)\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('num', numeric_transformer, numeric_features),\n",
    "                ('cat', categorical_transformer, categorical_features)])\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('regressor', LinearRegression())])\n",
    "        search_space = [{'regressor': [LinearRegression()],\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor':[Ridge()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [Lasso()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [ElasticNet()],\n",
    "                        'regressor__l1_ratio': np.linspace(0,1,30),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [RandomForestRegressor()],\n",
    "                        'regressor__n_estimators': np.logspace(2,3,20),\n",
    "                        'regressor__max_depth': np.linspace(1,10,10),\n",
    "                        'regressor__criterion': ['mse', 'mae']}]\n",
    "        \n",
    "        reg_CV = GridSearchCV(reg, search_space, cv=5, n_jobs=-1)\n",
    "        best_model = reg_CV.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        df_best_regressor = best_model.best_estimator_.get_params()['regressor']\n",
    "        R2 = r2_score(y_test, y_pred)\n",
    "        MSE = mean_squared_error(y_test, y_pred)\n",
    "        RMSE = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        MAE = mean_absolute_error(y_test, y_pred)\n",
    "        results = pd.DataFrame({\"R2\": R2, 'MSE':MSE, 'RMSE': RMSE, 'MAE':MAE, 'best regressor':                 df_best_regressor}, index=[key])\n",
    "        dfresults = dfresults.append(results)\n",
    "print(dfresults)"
   ]
  },
  {
   "source": [
    "# CLassification Model Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1000, 3), indices imply (1, 3)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-cfcdc5ce649f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mMAE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         results = pd.DataFrame({\"R2\": R2, 'MSE':MSE, 'RMSE': RMSE, 'MAE':MAE, 'best regressor':                 df_best_regressor}, index=[key])'''\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"Accuracy\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'f1'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'best classifier'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdf_best_classifier\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[0mdfresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Springboard\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Springboard\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         ]\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Springboard\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Springboard\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[1;34m(arrays, names, axes)\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1688\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Springboard\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[1;34m(arrays, names, axes)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mform_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1684\u001b[1;33m         \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1685\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Springboard\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;31m# Populate known_consolidate, blknos, and blklocs lazily\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Springboard\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mconstruction_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (1000, 3), indices imply (1, 3)"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.metrics import accuracy_score,log_loss\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "dfdict = {'year':year, 'yearAV':yearAV, 'week':week,'weekAV':weekAV, 'yearnocoach': yearnocoach,                        'yearnocoachAV':yearnocoachAV}\n",
    "\n",
    "\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftPosition', axis=1)\n",
    "        y = df['DraftPosition']\n",
    "        categorical_features = list(X.select_dtypes(include=['category', object]).columns)\n",
    "        categorical_transformer = make_pipeline(OneHotEncoder(sparse=True, handle_unknown='ignore'))\n",
    "\n",
    "        numeric_features = list(X.select_dtypes(include=['int', 'float']).columns)\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('num', numeric_transformer, numeric_features),\n",
    "                ('cat', categorical_transformer, categorical_features)])\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('classifier', RandomForestClassifier())])\n",
    "        search_space = [{'classifier': [RandomForestClassifier()],\n",
    "                        'classifier__n_estimators': [100,500,1000],\n",
    "                        'classifier__criterion': ['gini', 'entropy']}]\n",
    "        \n",
    "        clf_CV = GridSearchCV(clf, search_space, cv=5, n_jobs=-1)\n",
    "        best_model = clf_CV.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        ac = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        df_best_classifier = best_model.best_estimator_.get_params()['classifier']\n",
    "        results = pd.DataFrame({\"Accuracy\": ac, 'f1': f1, 'best classifier': df_best_classifier}, index=[key])\n",
    "        dfresults = dfresults.append(results)\n",
    "print(dfresults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}