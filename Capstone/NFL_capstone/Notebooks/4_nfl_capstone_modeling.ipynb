{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.3 64-bit ('Springboard': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c89e3a547b31aeddc31efee464a9a300846520c3802d37af32d3efdc899ae2c5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# NFL Capstone:Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Starting Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "source": [
    "## Import datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = pd.read_csv('../data/teamstarterdraft.csv')\n",
    "yearAV = pd.read_csv('../data/teamstarterdraftAV.csv')\n",
    "week = pd.read_csv('../data/weekstarterdraft.csv')\n",
    "weekAV = pd.read_csv('../data/weekstarterdraftAV.csv')\n",
    "yearnocoach = year.drop(columns=['coach', 'offcoor', 'defcoor', 'offscheme', 'defalign'])\n",
    "yearnocoachAV = yearAV.drop(columns=['coach', 'offcoor', 'defcoor', 'offscheme', 'defalign'])"
   ]
  },
  {
   "source": [
    "## New Datasets with bucketization of major categorical variables and ordinal encoding of weeks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekord = week.copy()\n",
    "weekAVord = weekAV.copy()\n",
    "weekord['Week'] = weekord['Week'].replace('Wild Card', 18)\n",
    "weekord['Week'] = weekord['Week'].replace('Division', 19)\n",
    "weekord['Week'] = weekord['Week'].replace('Conf. Champ.', 20)\n",
    "weekord['Week'] = weekord['Week'].replace('SuperBowl', 21)\n",
    "\n",
    "weekAVord['Week'] = weekAVord['Week'].replace('Wild Card', 18)\n",
    "weekAVord['Week'] = weekAVord['Week'].replace('Division', 19)\n",
    "weekAVord['Week'] = weekAVord['Week'].replace('Conf. Champ.', 20)\n",
    "weekAVord['Week'] = weekAVord['Week'].replace('SuperBowl', 21)\n",
    "\n",
    "weekord['Week']= weekord['Week'].astype(int)\n",
    "weekAVord['Week']= weekAVord['Week'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearbucket = year.copy()\n",
    "yearAVbucket = yearAV.copy()\n",
    "top = yearbucket['coach'].isin(yearbucket['coach'].value_counts().index[:61])\n",
    "yearbucket.loc[~top, 'coach'] = 'other'\n",
    "\n",
    "top = yearbucket['offcoor'].isin(yearbucket['offcoor'].value_counts().index[:61])\n",
    "yearbucket.loc[~top, 'offcoor'] = 'other'\n",
    "\n",
    "top = yearbucket['defcoor'].isin(yearbucket['defcoor'].value_counts().index[:61])\n",
    "yearAVbucket.loc[~top, 'defcoor'] = 'other'\n",
    "\n",
    "top = yearAVbucket['coach'].isin(yearAVbucket['coach'].value_counts().index[:61])\n",
    "yearAVbucket.loc[~top, 'coach'] = 'other'\n",
    "\n",
    "top = yearAVbucket['offcoor'].isin(yearAVbucket['offcoor'].value_counts().index[:61])\n",
    "yearAVbucket.loc[~top, 'offcoor'] = 'other'\n",
    "\n",
    "top = yearAVbucket['defcoor'].isin(yearAVbucket['defcoor'].value_counts().index[:61])\n",
    "yearAVbucket.loc[~top, 'defcoor'] = 'other'"
   ]
  },
  {
   "source": [
    "# Model Selection Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                     R2       MSE      RMSE       MAE  \\\nyear           0.003490  6.803684  2.608387  2.203176   \nyearAV         0.000286  6.996596  2.645108  2.220828   \nweek           0.027038  6.751551  2.598375  2.174834   \nweekAV         0.038667  6.563252  2.561884  2.143305   \nyearnocoach    0.010850  6.734904  2.595169  2.183651   \nyearnocoachAV  0.003437  6.907644  2.628240  2.184574   \n\n                                                  best regressor  \nyear           ElasticNet(alpha=1.0, copy_X=True, fit_interce...  \nyearAV         Lasso(alpha=0.15264179671752318, copy_X=True, ...  \nweek           Lasso(alpha=0.0009540954763499944, copy_X=True...  \nweekAV         Lasso(alpha=0.0011513953993264468, copy_X=True...  \nyearnocoach    Ridge(alpha=1.0, copy_X=True, fit_intercept=Tr...  \nyearnocoachAV  Ridge(alpha=1.0, copy_X=True, fit_intercept=Tr...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "dfdict = {'year':year, 'yearAV':yearAV, 'week':week,'weekAV':weekAV, 'yearnocoach': yearnocoach, 'yearnocoachAV':yearnocoachAV}\n",
    "\n",
    "\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftTeamSelection', axis=1)\n",
    "        y = df['DraftTeamSelection']\n",
    "        \n",
    "        categorical_features = list(X.select_dtypes(include=['category', object]).columns)\n",
    "        categorical_transformer = OneHotEncoder(sparse=True, handle_unknown='ignore')\n",
    "\n",
    "        numeric_features = list(X.select_dtypes(include=['int', 'float']).columns)\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('num', numeric_transformer, numeric_features),\n",
    "                ('cat', categorical_transformer, categorical_features)])\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('regressor', LinearRegression())])\n",
    "        search_space = [{'regressor': [LinearRegression()],\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor':[Ridge()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [Lasso()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [ElasticNet()],\n",
    "                        'regressor__l1_ratio': np.linspace(0,1,30),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [RandomForestRegressor()],\n",
    "                        'regressor__n_estimators': np.logspace(2,3,20),\n",
    "                        'regressor__max_depth': np.linspace(1,10,10),\n",
    "                        'regressor__criterion': ['mse', 'mae']}]\n",
    "        \n",
    "        reg_CV = GridSearchCV(reg, search_space, cv=5, n_jobs=-1)\n",
    "        best_model = reg_CV.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        df_best_regressor = best_model.best_estimator_.get_params()['regressor']\n",
    "        R2 = r2_score(y_test, y_pred)\n",
    "        MSE = mean_squared_error(y_test, y_pred)\n",
    "        RMSE = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        MAE = mean_absolute_error(y_test, y_pred)\n",
    "        results = pd.DataFrame({\"R2\": R2, 'MSE':MSE, 'RMSE': RMSE, 'MAE':MAE, 'best regressor':                 df_best_regressor}, index=[key])\n",
    "        dfresults = dfresults.append(results)\n",
    "print(dfresults)"
   ]
  },
  {
   "source": [
    "# Model Selection Regression w/ PCA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "               PCA components        R2       MSE      RMSE       MAE  \\\nyear                       50  0.006157  6.564303  2.562090  2.148639   \nyearAV                     50 -0.000032  7.133128  2.670792  2.246177   \nweek                       50  0.012887  6.832590  2.613922  2.188608   \nweekAV                     50  0.016964  6.642123  2.577232  2.155551   \nyearnocoach                50 -0.005583  7.053212  2.655788  2.221354   \nyearnocoachAV               2 -0.004378  7.119864  2.668307  2.228804   \n\n                                                  best regressor  \nyear           Ridge(alpha=1.0, copy_X=True, fit_intercept=Tr...  \nyearAV         Lasso(alpha=0.0011513953993264468, copy_X=True...  \nweek           Ridge(alpha=0.007543120063354615, copy_X=True,...  \nweekAV         Lasso(alpha=0.004291934260128779, copy_X=True,...  \nyearnocoach    Ridge(alpha=0.6866488450042998, copy_X=True, f...  \nyearnocoachAV  Ridge(alpha=0.15264179671752318, copy_X=True, ...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "dfdict = {'year':year, 'yearAV':yearAV, 'week':week,'weekAV':weekAV, 'yearnocoach': yearnocoach, 'yearnocoachAV':yearnocoachAV}\n",
    "\n",
    "\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftTeamSelection', axis=1)\n",
    "        y = df['DraftTeamSelection']\n",
    "        \n",
    "        categorical_features = list(X.select_dtypes(include=['category', object]).columns)\n",
    "        categorical_transformer = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "        numeric_features = list(X.select_dtypes(include=['int', 'float']).columns)\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('num', numeric_transformer, numeric_features),\n",
    "                ('cat', categorical_transformer, categorical_features)])\n",
    "        \n",
    "        pca = PCA()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('pca', pca),\n",
    "                                ('regressor', LinearRegression())])\n",
    "        search_space = [{'pca__n_components':[2,15,30,50,100],\n",
    "                        'regressor': [LinearRegression()],\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'pca__n_components':[2,15,30,50,100],\n",
    "                        'regressor':[Ridge()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'pca__n_components':[2,15,30,50,100],\n",
    "                        'regressor': [Lasso()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'pca__n_components':[2,15,30,50,100],\n",
    "                        'regressor': [ElasticNet()],\n",
    "                        'regressor__l1_ratio': np.linspace(0,1,30),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'pca__n_components':[2,15,30,50,100],\n",
    "                        'regressor': [RandomForestRegressor()],\n",
    "                        'regressor__n_estimators': np.logspace(2,3,20),\n",
    "                        'regressor__max_depth': np.linspace(1,10,10),\n",
    "                        'regressor__criterion': ['mse', 'mae']}]\n",
    "        \n",
    "        reg_CV = GridSearchCV(reg, search_space, cv=5, n_jobs=-1)\n",
    "        best_model = reg_CV.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        df_best_regressor = best_model.best_estimator_.get_params()['regressor']\n",
    "        R2 = r2_score(y_test, y_pred)\n",
    "        MSE = mean_squared_error(y_test, y_pred)\n",
    "        RMSE = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        MAE = mean_absolute_error(y_test, y_pred)\n",
    "        pca_components = reg_CV.best_estimator_.named_steps['pca'].n_components\n",
    "        results = pd.DataFrame({'PCA components': pca_components, \"R2\": R2, 'MSE':MSE, 'RMSE': RMSE, 'MAE':MAE, 'best regressor': df_best_regressor}, index=[key])\n",
    "        dfresults = dfresults.append(results)\n",
    "print(dfresults)"
   ]
  },
  {
   "source": [
    "# Model Selection Regresson run on datasets with bucketized coach values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    R2       MSE      RMSE       MAE  \\\nyearbucket    0.002520  7.142888  2.672618  2.240276   \nyearAVbucket  0.013071  6.455497  2.540767  2.151045   \nweek          0.024096  6.787724  2.605326  2.179035   \nweekAV        0.041493  6.602885  2.569608  2.149873   \n\n                                                 best regressor  \nyearbucket    Lasso(alpha=0.0016768329368110067, copy_X=True...  \nyearAVbucket  Lasso(alpha=0.0020235896477251557, copy_X=True...  \nweek          Ridge(alpha=0.04941713361323833, copy_X=True, ...  \nweekAV        Ridge(alpha=0.040949150623804234, copy_X=True,...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#this is what I changed from cell above\n",
    "dfdict = {'yearbucket':yearbucket, 'yearAVbucket':yearAVbucket, 'week':weekord,'weekAV':weekAVord}\n",
    "\n",
    "\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftTeamSelection', axis=1)\n",
    "        y = df['DraftTeamSelection']\n",
    "        categorical_features = list(df.select_dtypes(include=['category', object]).columns)\n",
    "        categorical_transformer = OneHotEncoder(sparse=True, handle_unknown='ignore')\n",
    "\n",
    "        numeric_features = list(df.select_dtypes(include=['int', 'float']).columns)\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('num', numeric_transformer, numeric_features),\n",
    "                ('cat', categorical_transformer, categorical_features)])\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('regressor', LinearRegression())])\n",
    "        search_space = [{'regressor': [LinearRegression()],\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor':[Ridge()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [Lasso()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [ElasticNet()],\n",
    "                        'regressor__l1_ratio': np.linspace(0,1,30),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [RandomForestRegressor()],\n",
    "                        'regressor__n_estimators': np.logspace(2,3,20),\n",
    "                        'regressor__max_depth': np.linspace(1,10,10),\n",
    "                        'regressor__criterion': ['mse', 'mae']}]\n",
    "        \n",
    "        reg_CV = GridSearchCV(reg, search_space, cv=5, n_jobs=-1)\n",
    "        best_model = reg_CV.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        df_best_regressor = best_model.best_estimator_.get_params()['regressor']\n",
    "        R2 = r2_score(y_test, y_pred)\n",
    "        MSE = mean_squared_error(y_test, y_pred)\n",
    "        RMSE = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        MAE = mean_absolute_error(y_test, y_pred)\n",
    "        results = pd.DataFrame({\"R2\": R2, 'MSE':MSE, 'RMSE': RMSE, 'MAE':MAE, 'best regressor':                 df_best_regressor}, index=[key])\n",
    "        dfresults = dfresults.append(results)\n",
    "print(dfresults)"
   ]
  },
  {
   "source": [
    "# Classification Model Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.1947405828002843\n",
      "0.06626291822802163\n",
      "SVC(C=0.25, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "0.20154291224686596\n",
      "0.06761230924493578\n",
      "SVC(C=0.25, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "0.26898788189110767\n",
      "0.24840054078670845\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.2669368847712797\n",
      "0.2524904613944206\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.20398009950248755\n",
      "0.07764515604913558\n",
      "SVC(C=0.25, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "0.19575699132111862\n",
      "0.09382311826751288\n",
      "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "               PCA components  Accuracy        f1\n",
      "year                       30  0.194741  0.066263\n",
      "yearAV                     15  0.201543  0.067612\n",
      "week                       15  0.268988  0.248401\n",
      "weekAV                      2  0.266937  0.252490\n",
      "yearnocoach                 2  0.203980  0.077645\n",
      "yearnocoachAV               2  0.195757  0.093823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "dfdict = {'year':year, 'yearAV':yearAV, 'week':week,'weekAV':weekAV, 'yearnocoach': yearnocoach, 'yearnocoachAV':yearnocoachAV}\n",
    "\n",
    "\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftPosition', axis=1)\n",
    "        y = df['DraftPosition']\n",
    "        #categorical_features = list(X.select_dtypes(include=['category', object]).columns)\n",
    "        #categorical_transformer = make_pipeline(OneHotEncoder(sparse=True, handle_unknown='ignore'))\n",
    "\n",
    "        numeric_features = list(X.select_dtypes(include=['int', 'float']).columns)\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('num', numeric_transformer, numeric_features)])\n",
    "                #('cat', categorical_transformer, categorical_features)])\n",
    "        pca = PCA()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('pca', pca),\n",
    "                                ('classifier', RandomForestClassifier())])\n",
    "        search_space = [{'pca__n_components':[2,15,30,50,100],\n",
    "                        'classifier': [RandomForestClassifier()],\n",
    "                        'classifier__n_estimators': [64,96,128,1000,2000],\n",
    "                        'classifier__criterion': ['gini', 'entropy']},\n",
    "                        {'pca__n_components':[2,15,30,50,100],\n",
    "                        'classifier': [SVC()],\n",
    "                        'classifier__C': [0.25, 0.50, 0.75, 1]}]\n",
    "        \n",
    "        clf_CV = GridSearchCV(clf, search_space, cv=5, n_jobs=-1)\n",
    "        best_model = clf_CV.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "\n",
    "        ac = accuracy_score(y_test, y_pred)\n",
    "        print(ac)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(f1)\n",
    "        #cm = confusion_matrix(y_test, y_pred)\n",
    "        df_best_classifier = best_model.best_estimator_.get_params()['classifier']\n",
    "        print(df_best_classifier)\n",
    "        pca_components = clf_CV.best_estimator_.named_steps['pca'].n_components\n",
    "        #,'best classifier': df_best_classifier\n",
    "        results = pd.DataFrame({'PCA components': pca_components, \"Accuracy\": ac, \"f1\" : f1}, index=[key])\n",
    "        dfresults = dfresults.append(results)\n",
    "print(dfresults)"
   ]
  },
  {
   "source": [
    "# Best dataset (week) vs dummy classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'Dataframe'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5b4f1ea250a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mdummy_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mdummy_score_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdummy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m \u001b[0mdummy_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdummy_score_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[0mac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'Dataframe'"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "\n",
    "X = week.drop('DraftPosition', axis=1)\n",
    "y = week['DraftPosition']\n",
    "#categorical_features = list(X.select_dtypes(include=['category', object]).columns)\n",
    "#categorical_transformer = make_pipeline(OneHotEncoder(sparse=True, handle_unknown='ignore'))\n",
    "\n",
    "numeric_features = list(X.select_dtypes(include=['int', 'float']).columns)\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[\n",
    "    ('num', numeric_transformer, numeric_features)])\n",
    "pca = PCA()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                    ('pca', pca),\n",
    "                    ('classifier', RandomForestClassifier())])\n",
    "search_space = [{'pca__n_components':[2,15,30,50,100],\n",
    "            'classifier': [RandomForestClassifier()],\n",
    "            'classifier__n_estimators': [64,96,128,1000,2000],\n",
    "            'classifier__criterion': ['gini', 'entropy']},\n",
    "            {'pca__n_components':[2,15,30,50,100],\n",
    "            'classifier': [SVC()],\n",
    "            'classifier__C': [0.25, 0.50, 0.75, 1],\n",
    "            'classifier__kernel': ['linear', 'poly', 'rbf', 'sigmoid']}]\n",
    "\n",
    "clf_CV = GridSearchCV(clf, search_space, cv=5, n_jobs=-1)\n",
    "\n",
    "best_model = clf_CV.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "cv_results_df = pd.DataFrame(clf_CV.cv_results_)\n",
    "cv_results_df = cv_results_df.sort_values(by=['rank_test_score'])\n",
    "cv_results_df = (\n",
    "    cv_results_df\n",
    "    .set_index(cv_results_df[\"params\"].apply(\n",
    "        lambda x: \"_\".join(str(val) for val in x.values()))\n",
    "    )\n",
    "    .rename_axis('params')\n",
    ")\n",
    "cv_results_df[\n",
    "    ['params', 'rank_test_score', 'mean_test_score', 'std_test_score']\n",
    "]\n",
    "\n",
    "dummy_score_dict = {}\n",
    "strategies = ['stratified', 'most_frequent', 'uniform']\n",
    "for strategy in strategies:\n",
    "    dclf = DummyClassifier(strategy=strategy)\n",
    "    dclf.fit(X_train, y_train)\n",
    "    dummy_score = dclf.score(X_test, y_test)\n",
    "    dummy_score_dict[strategy] = dummy_score\n",
    "dummy_df = pd.DataFrame.from_dict(dummy_score_dict)\n",
    "\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "#print(ac)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "#print(f1)\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "df_best_classifier = best_model.best_estimator_.get_params()['classifier']\n",
    "print(df_best_classifier)\n",
    "pca_components = clf_CV.best_estimator_.named_steps['pca'].n_components\n",
    "#,'best classifier': df_best_classifier\n",
    "results = pd.DataFrame({'PCA components': pca_components, \"Accuracy\": ac, \"f1\" : f1}, index=[key])\n",
    "\n",
    "\n",
    "\n",
    "print(dummy_df)\n",
    "print(cv_results_df)\n",
    "print(results)"
   ]
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}