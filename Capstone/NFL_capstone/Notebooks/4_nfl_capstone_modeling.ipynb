{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# NFL Capstone:Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Starting Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "source": [
    "## Import datasets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = pd.read_csv('../data/teamstarterdraft.csv')\n",
    "yearAV = pd.read_csv('../data/teamstarterdraftAV.csv')\n",
    "week = pd.read_csv('../data/weekstarterdraft.csv')\n",
    "weekAV = pd.read_csv('../data/weekstarterdraftAV.csv')\n",
    "yearnocoach = year.drop(columns=['coach', 'offcoor', 'defcoor', 'offscheme', 'defalign'])\n",
    "yearnocoachAV = yearAV.drop(columns=['coach', 'offcoor', 'defcoor', 'offscheme', 'defalign'])"
   ]
  },
  {
   "source": [
    "## New Datasets with bucketization of major categorical variables and ordinal encoding of weeks"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekord = week.copy()\n",
    "weekAVord = weekAV.copy()\n",
    "weekord['Week'] = weekord['Week'].replace('Wild Card', 18)\n",
    "weekord['Week'] = weekord['Week'].replace('Division', 19)\n",
    "weekord['Week'] = weekord['Week'].replace('Conf. Champ.', 20)\n",
    "weekord['Week'] = weekord['Week'].replace('SuperBowl', 21)\n",
    "\n",
    "weekAVord['Week'] = weekAVord['Week'].replace('Wild Card', 18)\n",
    "weekAVord['Week'] = weekAVord['Week'].replace('Division', 19)\n",
    "weekAVord['Week'] = weekAVord['Week'].replace('Conf. Champ.', 20)\n",
    "weekAVord['Week'] = weekAVord['Week'].replace('SuperBowl', 21)\n",
    "\n",
    "weekord['Week']= weekord['Week'].astype(int)\n",
    "weekAVord['Week']= weekAVord['Week'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearbucket = year.copy()\n",
    "yearAVbucket = yearAV.copy()\n",
    "top = yearbucket['coach'].isin(yearbucket['coach'].value_counts().index[:61])\n",
    "yearbucket.loc[~top, 'coach'] = 'other'\n",
    "\n",
    "top = yearbucket['offcoor'].isin(yearbucket['offcoor'].value_counts().index[:61])\n",
    "yearbucket.loc[~top, 'offcoor'] = 'other'\n",
    "\n",
    "top = yearbucket['defcoor'].isin(yearbucket['defcoor'].value_counts().index[:61])\n",
    "yearAVbucket.loc[~top, 'defcoor'] = 'other'\n",
    "\n",
    "top = yearAVbucket['coach'].isin(yearAVbucket['coach'].value_counts().index[:61])\n",
    "yearAVbucket.loc[~top, 'coach'] = 'other'\n",
    "\n",
    "top = yearAVbucket['offcoor'].isin(yearAVbucket['offcoor'].value_counts().index[:61])\n",
    "yearAVbucket.loc[~top, 'offcoor'] = 'other'\n",
    "\n",
    "top = yearAVbucket['defcoor'].isin(yearAVbucket['defcoor'].value_counts().index[:61])\n",
    "yearAVbucket.loc[~top, 'defcoor'] = 'other'"
   ]
  },
  {
   "source": [
    "# Model Selection Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                     R2       MSE      RMSE       MAE  \\\nyear           0.003490  6.803684  2.608387  2.203176   \nyearAV         0.000286  6.996596  2.645108  2.220828   \nweek           0.027038  6.751551  2.598375  2.174834   \nweekAV         0.038667  6.563252  2.561884  2.143305   \nyearnocoach    0.010850  6.734904  2.595169  2.183651   \nyearnocoachAV  0.003437  6.907644  2.628240  2.184574   \n\n                                                  best regressor  \nyear           ElasticNet(alpha=1.0, copy_X=True, fit_interce...  \nyearAV         Lasso(alpha=0.15264179671752318, copy_X=True, ...  \nweek           Lasso(alpha=0.0009540954763499944, copy_X=True...  \nweekAV         Lasso(alpha=0.0011513953993264468, copy_X=True...  \nyearnocoach    Ridge(alpha=1.0, copy_X=True, fit_intercept=Tr...  \nyearnocoachAV  Ridge(alpha=1.0, copy_X=True, fit_intercept=Tr...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "dfdict = {'year':year, 'yearAV':yearAV, 'week':week,'weekAV':weekAV, 'yearnocoach': yearnocoach, 'yearnocoachAV':yearnocoachAV}\n",
    "\n",
    "\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftTeamSelection', axis=1)\n",
    "        y = df['DraftTeamSelection']\n",
    "        \n",
    "        categorical_features = list(X.select_dtypes(include=['category', object]).columns)\n",
    "        categorical_transformer = OneHotEncoder(sparse=True, handle_unknown='ignore')\n",
    "\n",
    "        numeric_features = list(X.select_dtypes(include=['int', 'float']).columns)\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('num', numeric_transformer, numeric_features),\n",
    "                ('cat', categorical_transformer, categorical_features)])\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('regressor', LinearRegression())])\n",
    "        search_space = [{'regressor': [LinearRegression()],\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor':[Ridge()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [Lasso()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [ElasticNet()],\n",
    "                        'regressor__l1_ratio': np.linspace(0,1,30),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [RandomForestRegressor()],\n",
    "                        'regressor__n_estimators': np.logspace(2,3,20),\n",
    "                        'regressor__max_depth': np.linspace(1,10,10),\n",
    "                        'regressor__criterion': ['mse', 'mae']}]\n",
    "        \n",
    "        reg_CV = GridSearchCV(reg, search_space, cv=5, n_jobs=-1)\n",
    "        best_model = reg_CV.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        df_best_regressor = best_model.best_estimator_.get_params()['regressor']\n",
    "        R2 = r2_score(y_test, y_pred)\n",
    "        MSE = mean_squared_error(y_test, y_pred)\n",
    "        RMSE = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        MAE = mean_absolute_error(y_test, y_pred)\n",
    "        results = pd.DataFrame({\"R2\": R2, 'MSE':MSE, 'RMSE': RMSE, 'MAE':MAE, 'best regressor': df_best_regressor}, index=[key])\n",
    "        dfresults = dfresults.append(results)\n",
    "print(dfresults)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "year (4261, 73) (4261, 497)\n",
      "yearAV (3140, 82) (3140, 448)\n",
      "week (71017, 34) (71017, 93)\n",
      "weekAV (52331, 43) (52331, 102)\n"
     ]
    }
   ],
   "source": [
    "dfdict = {'year':year, 'yearAV':yearAV, 'week':week,'weekAV':weekAV}\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftTeamSelection', axis=1)\n",
    "        y = df['DraftTeamSelection']\n",
    "\n",
    "        X_dummies = pd.get_dummies(X)\n",
    "        print(key, X.shape, X_dummies.shape)\n"
   ]
  },
  {
   "source": [
    "# Model Selection Regression w/ PCA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "               PCA components        R2       MSE      RMSE       MAE  \\\nyear                       50  0.006157  6.564303  2.562090  2.148639   \nyearAV                     50 -0.000032  7.133128  2.670792  2.246177   \nweek                       50  0.012887  6.832590  2.613922  2.188608   \nweekAV                     50  0.016964  6.642123  2.577232  2.155551   \nyearnocoach                50 -0.005583  7.053212  2.655788  2.221354   \nyearnocoachAV               2 -0.004378  7.119864  2.668307  2.228804   \n\n                                                  best regressor  \nyear           Ridge(alpha=1.0, copy_X=True, fit_intercept=Tr...  \nyearAV         Lasso(alpha=0.0011513953993264468, copy_X=True...  \nweek           Ridge(alpha=0.007543120063354615, copy_X=True,...  \nweekAV         Lasso(alpha=0.004291934260128779, copy_X=True,...  \nyearnocoach    Ridge(alpha=0.6866488450042998, copy_X=True, f...  \nyearnocoachAV  Ridge(alpha=0.15264179671752318, copy_X=True, ...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "dfdict = {'year':year, 'yearAV':yearAV, 'week':week,'weekAV':weekAV, 'yearnocoach': yearnocoach, 'yearnocoachAV':yearnocoachAV}\n",
    "\n",
    "\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftTeamSelection', axis=1)\n",
    "        y = df['DraftTeamSelection']\n",
    "        \n",
    "        categorical_features = list(X.select_dtypes(include=['category', object]).columns)\n",
    "        categorical_transformer = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "        numeric_features = list(X.select_dtypes(include=['int', 'float']).columns)\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('num', numeric_transformer, numeric_features),\n",
    "                ('cat', categorical_transformer, categorical_features)])\n",
    "        \n",
    "        pca = PCA()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('pca', pca),\n",
    "                                ('regressor', LinearRegression())])\n",
    "        search_space = [{'pca__n_components':[2,15,30,50,100],\n",
    "                        'regressor': [LinearRegression()],\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'pca__n_components':[2,15,30,50,100],\n",
    "                        'regressor':[Ridge()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'pca__n_components':[2,15,30,50,100],\n",
    "                        'regressor': [Lasso()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'pca__n_components':[2,15,30,50,100],\n",
    "                        'regressor': [ElasticNet()],\n",
    "                        'regressor__l1_ratio': np.linspace(0,1,30),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'pca__n_components':[2,15,30,50,100],\n",
    "                        'regressor': [RandomForestRegressor()],\n",
    "                        'regressor__n_estimators': np.logspace(2,3,20),\n",
    "                        'regressor__max_depth': np.linspace(1,10,10),\n",
    "                        'regressor__criterion': ['mse', 'mae']}]\n",
    "        \n",
    "        reg_CV = GridSearchCV(reg, search_space, cv=5, n_jobs=-1)\n",
    "        best_model = reg_CV.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        df_best_regressor = best_model.best_estimator_.get_params()['regressor']\n",
    "        R2 = r2_score(y_test, y_pred)\n",
    "        MSE = mean_squared_error(y_test, y_pred)\n",
    "        RMSE = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        MAE = mean_absolute_error(y_test, y_pred)\n",
    "        pca_components = reg_CV.best_estimator_.named_steps['pca'].n_components\n",
    "        results = pd.DataFrame({'PCA components': pca_components, \"R2\": R2, 'MSE':MSE, 'RMSE': RMSE, 'MAE':MAE, 'best regressor': df_best_regressor}, index=[key])\n",
    "        dfresults = dfresults.append(results)\n",
    "print(dfresults)"
   ]
  },
  {
   "source": [
    "# Model Selection Regresson run on datasets with bucketized coach values"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    R2       MSE      RMSE       MAE  \\\nyearbucket    0.002520  7.142888  2.672618  2.240276   \nyearAVbucket  0.013071  6.455497  2.540767  2.151045   \nweek          0.024096  6.787724  2.605326  2.179035   \nweekAV        0.041493  6.602885  2.569608  2.149873   \n\n                                                 best regressor  \nyearbucket    Lasso(alpha=0.0016768329368110067, copy_X=True...  \nyearAVbucket  Lasso(alpha=0.0020235896477251557, copy_X=True...  \nweek          Ridge(alpha=0.04941713361323833, copy_X=True, ...  \nweekAV        Ridge(alpha=0.040949150623804234, copy_X=True,...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#this is what I changed from cell above\n",
    "dfdict = {'yearbucket':yearbucket, 'yearAVbucket':yearAVbucket, 'week':weekord,'weekAV':weekAVord}\n",
    "\n",
    "\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftTeamSelection', axis=1)\n",
    "        y = df['DraftTeamSelection']\n",
    "        categorical_features = list(df.select_dtypes(include=['category', object]).columns)\n",
    "        categorical_transformer = OneHotEncoder(sparse=True, handle_unknown='ignore')\n",
    "\n",
    "        numeric_features = list(df.select_dtypes(include=['int', 'float']).columns)\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('num', numeric_transformer, numeric_features),\n",
    "                ('cat', categorical_transformer, categorical_features)])\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        reg = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('regressor', LinearRegression())])\n",
    "        search_space = [{'regressor': [LinearRegression()],\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor':[Ridge()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [Lasso()],\n",
    "                        'regressor__alpha': np.logspace(-4, 0, 50),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [ElasticNet()],\n",
    "                        'regressor__l1_ratio': np.linspace(0,1,30),\n",
    "                        'regressor__normalize': [True, False]},\n",
    "                        {'regressor': [RandomForestRegressor()],\n",
    "                        'regressor__n_estimators': np.logspace(2,3,20),\n",
    "                        'regressor__max_depth': np.linspace(1,10,10),\n",
    "                        'regressor__criterion': ['mse', 'mae']}]\n",
    "        \n",
    "        reg_CV = GridSearchCV(reg, search_space, cv=5, n_jobs=-1)\n",
    "        best_model = reg_CV.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        \n",
    "        df_best_regressor = best_model.best_estimator_.get_params()['regressor']\n",
    "        R2 = r2_score(y_test, y_pred)\n",
    "        MSE = mean_squared_error(y_test, y_pred)\n",
    "        RMSE = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        MAE = mean_absolute_error(y_test, y_pred)\n",
    "        results = pd.DataFrame({\"R2\": R2, 'MSE':MSE, 'RMSE': RMSE, 'MAE':MAE, 'best regressor':                 df_best_regressor}, index=[key])\n",
    "        dfresults = dfresults.append(results)\n",
    "print(dfresults)"
   ]
  },
  {
   "source": [
    "# Classification Model Selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.20540156361051884\n",
      "0.08477457890001086\n",
      "SVC(C=0.25, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "0.20154291224686596\n",
      "0.06761230924493578\n",
      "SVC(C=0.25, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "0.269115890083632\n",
      "0.24101193239029695\n",
      "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "0.2688477127967574\n",
      "0.25192539054479235\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=128,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "0.1968727789623312\n",
      "0.06507804108386216\n",
      "SVC(C=0.25, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "0.20057859209257473\n",
      "0.06702063800041053\n",
      "SVC(C=0.25, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "               PCA components  Accuracy        f1\n",
      "year                        2  0.205402  0.084775\n",
      "yearAV                     15  0.201543  0.067612\n",
      "week                       15  0.269116  0.241012\n",
      "weekAV                     15  0.268848  0.251925\n",
      "yearnocoach                30  0.196873  0.065078\n",
      "yearnocoachAV              30  0.200579  0.067021\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "dfdict = {'year':year, 'yearAV':yearAV, 'week':week,'weekAV':weekAV, 'yearnocoach': yearnocoach, 'yearnocoachAV':yearnocoachAV}\n",
    "\n",
    "\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftPosition', axis=1)\n",
    "        y = df['DraftPosition']\n",
    "        #categorical_features = list(X.select_dtypes(include=['category', object]).columns)\n",
    "        #categorical_transformer = make_pipeline(OneHotEncoder(sparse=True, handle_unknown='ignore'))\n",
    "\n",
    "        numeric_features = list(X.select_dtypes(include=['int', 'float']).columns)\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('num', numeric_transformer, numeric_features)])\n",
    "                #('cat', categorical_transformer, categorical_features)])\n",
    "        pca = PCA()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('pca', pca),\n",
    "                                ('classifier', RandomForestClassifier())])\n",
    "        search_space = [{'pca__n_components':[2,15,30,50,100],\n",
    "                        'classifier': [RandomForestClassifier()],\n",
    "                        'classifier__n_estimators': [64,96,128,1000,2000],\n",
    "                        'classifier__criterion': ['gini', 'entropy']},\n",
    "                        {'pca__n_components':[2,15,30,50,100],\n",
    "                        'classifier': [SVC()],\n",
    "                        'classifier__C': [0.25, 0.50, 0.75, 1]}]\n",
    "        \n",
    "        clf_CV = GridSearchCV(clf, search_space, cv=5, n_jobs=-1)\n",
    "        best_model = clf_CV.fit(X_train, y_train)\n",
    "        y_pred = best_model.predict(X_test)\n",
    " \n",
    "        ac = accuracy_score(y_test, y_pred)\n",
    "        print(ac)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(f1)\n",
    "        #cm = confusion_matrix(y_test, y_pred)\n",
    "        df_best_classifier = best_model.best_estimator_.get_params()['classifier']\n",
    "        print(df_best_classifier)\n",
    "        pca_components = clf_CV.best_estimator_.named_steps['pca'].n_components\n",
    "        #,'best classifier': df_best_classifier\n",
    "        results = pd.DataFrame({'PCA components': pca_components, \"Accuracy\": ac, \"f1\" : f1}, index=[key])\n",
    "        dfresults = dfresults.append(results)\n",
    "print(dfresults)"
   ]
  },
  {
   "source": [
    "# Best dataset (week) vs dummy classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   45.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 60.9min\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 76.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 76.2min finished\n"
     ]
    }
   ],
   "source": [
    "#No depth limit no pca\n",
    "dfdict = {'week':week}\n",
    "\n",
    "\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftPosition', axis=1)\n",
    "        y = df['DraftPosition']\n",
    "        #categorical_features = list(X.select_dtypes(include=['category', object]).columns)\n",
    "        #categorical_transformer = make_pipeline(OneHotEncoder(sparse=True, handle_unknown='ignore'))\n",
    "\n",
    "        numeric_features = list(X.select_dtypes(include=['int', 'float']).columns)\n",
    "        scalers_to_test = [StandardScaler(), MinMaxScaler()]\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', MinMaxScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('num', numeric_transformer, numeric_features)])\n",
    "                #('cat', categorical_transformer, categorical_features)])\n",
    "        pca = PCA()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('classifier', RandomForestClassifier())])\n",
    "        search_space = [{'classifier': [RandomForestClassifier()],\n",
    "                        'classifier__n_estimators': [64,96,128, 256],                         \n",
    "                        'classifier__criterion': ['gini', 'entropy']},\n",
    "                        {'classifier': [SVC()],\n",
    "                        'classifier__C': [0.25, 1],\n",
    "                        'classifier__kernel': ['poly', 'rbf']}]\n",
    "        \n",
    "        clf_CV = GridSearchCV(clf, search_space, cv=5, n_jobs=-1, verbose=10)\n",
    "        best_model = clf_CV.fit(X_train, y_train)\n",
    "        #saving model (https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/)\n",
    "        filename = 'best_model_no_pruning.sav'\n",
    "        pickle.dump(best_model, open(filename, 'wb'))##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-Validation best parameters:  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=64,\n",
      "                       n_jobs=None, oob_score=False, random_state=None,\n",
      "                       verbose=0, warm_start=False)\n",
      "Cross-validation mean test score: 0.4587754472064172\n",
      "                  score\n",
      "stratified     0.129459\n",
      "most_frequent  0.202936\n",
      "uniform        0.107996\n",
      "      Train Accuracy  Test Accuracy  Train F1   Test F1\n",
      "week             1.0       0.434332       1.0  0.432814\n",
      "[[2477  263  227  373  483  102  268  180  383]\n",
      " [ 319  896   72  132  264   68  105   96  178]\n",
      " [ 274   75  832  186  198   64  127   81  137]\n",
      " [ 402  154  142 1246  394  129  140  121  232]\n",
      " [ 512  192  183  397 1862   96  236  100  301]\n",
      " [ 137   63   88  155  104  442   74   24   61]\n",
      " [ 370  130  145  178  281   75  763   74  207]\n",
      " [ 203  112   69  178  121   35  112  415  134]\n",
      " [ 487  173  161  240  325   69  187   99 1246]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          DB       0.48      0.52      0.50      4756\n",
      "          DE       0.44      0.42      0.43      2130\n",
      "          DT       0.43      0.42      0.43      1974\n",
      "          LB       0.40      0.42      0.41      2960\n",
      "          OL       0.46      0.48      0.47      3879\n",
      "          QB       0.41      0.39      0.40      1148\n",
      "          RB       0.38      0.34      0.36      2223\n",
      "          TE       0.35      0.30      0.32      1379\n",
      "          WR       0.43      0.42      0.42      2987\n",
      "\n",
      "    accuracy                           0.43     23436\n",
      "   macro avg       0.42      0.41      0.42     23436\n",
      "weighted avg       0.43      0.43      0.43     23436\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "4      22.663899      0.448551         0.586909        0.044231   \n",
       "0      20.374341      0.907940         0.912101        0.177165   \n",
       "1      28.361846      0.308601         1.050777        0.149217   \n",
       "5      45.348789      3.549338         1.038997        0.265559   \n",
       "2      38.513515      0.670985         1.566372        0.286328   \n",
       "\n",
       "                                    param_classifier  \\\n",
       "4  RandomForestClassifier(bootstrap=True, ccp_alp...   \n",
       "0  RandomForestClassifier(bootstrap=True, ccp_alp...   \n",
       "1  RandomForestClassifier(bootstrap=True, ccp_alp...   \n",
       "5  RandomForestClassifier(bootstrap=True, ccp_alp...   \n",
       "2  RandomForestClassifier(bootstrap=True, ccp_alp...   \n",
       "\n",
       "  param_classifier__criterion param_classifier__n_estimators  \\\n",
       "4                     entropy                             64   \n",
       "0                        gini                             64   \n",
       "1                        gini                             96   \n",
       "5                     entropy                             96   \n",
       "2                        gini                            128   \n",
       "\n",
       "  param_classifier__C param_classifier__kernel  \\\n",
       "4                 NaN                      NaN   \n",
       "0                 NaN                      NaN   \n",
       "1                 NaN                      NaN   \n",
       "5                 NaN                      NaN   \n",
       "2                 NaN                      NaN   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "4  {'classifier': RandomForestClassifier(bootstra...           0.464222   \n",
       "0  {'classifier': RandomForestClassifier(bootstra...           0.456867   \n",
       "1  {'classifier': RandomForestClassifier(bootstra...           0.450562   \n",
       "5  {'classifier': RandomForestClassifier(bootstra...           0.448250   \n",
       "2  {'classifier': RandomForestClassifier(bootstra...           0.437848   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "4           0.449138           0.452291           0.444725           0.483501   \n",
       "0           0.478352           0.445670           0.449559           0.444409   \n",
       "1           0.456494           0.419714           0.444515           0.457125   \n",
       "5           0.449664           0.451135           0.426965           0.447352   \n",
       "2           0.457020           0.439155           0.447037           0.441467   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "4         0.458775        0.013953                1  \n",
       "0         0.454971        0.012471                2  \n",
       "1         0.445682        0.013765                3  \n",
       "5         0.444673        0.008947                4  \n",
       "2         0.444505        0.007003                5  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_classifier</th>\n      <th>param_classifier__criterion</th>\n      <th>param_classifier__n_estimators</th>\n      <th>param_classifier__C</th>\n      <th>param_classifier__kernel</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>22.663899</td>\n      <td>0.448551</td>\n      <td>0.586909</td>\n      <td>0.044231</td>\n      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n      <td>entropy</td>\n      <td>64</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'classifier': RandomForestClassifier(bootstra...</td>\n      <td>0.464222</td>\n      <td>0.449138</td>\n      <td>0.452291</td>\n      <td>0.444725</td>\n      <td>0.483501</td>\n      <td>0.458775</td>\n      <td>0.013953</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>20.374341</td>\n      <td>0.907940</td>\n      <td>0.912101</td>\n      <td>0.177165</td>\n      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n      <td>gini</td>\n      <td>64</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'classifier': RandomForestClassifier(bootstra...</td>\n      <td>0.456867</td>\n      <td>0.478352</td>\n      <td>0.445670</td>\n      <td>0.449559</td>\n      <td>0.444409</td>\n      <td>0.454971</td>\n      <td>0.012471</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>28.361846</td>\n      <td>0.308601</td>\n      <td>1.050777</td>\n      <td>0.149217</td>\n      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n      <td>gini</td>\n      <td>96</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'classifier': RandomForestClassifier(bootstra...</td>\n      <td>0.450562</td>\n      <td>0.456494</td>\n      <td>0.419714</td>\n      <td>0.444515</td>\n      <td>0.457125</td>\n      <td>0.445682</td>\n      <td>0.013765</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>45.348789</td>\n      <td>3.549338</td>\n      <td>1.038997</td>\n      <td>0.265559</td>\n      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n      <td>entropy</td>\n      <td>96</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'classifier': RandomForestClassifier(bootstra...</td>\n      <td>0.448250</td>\n      <td>0.449664</td>\n      <td>0.451135</td>\n      <td>0.426965</td>\n      <td>0.447352</td>\n      <td>0.444673</td>\n      <td>0.008947</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38.513515</td>\n      <td>0.670985</td>\n      <td>1.566372</td>\n      <td>0.286328</td>\n      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n      <td>gini</td>\n      <td>128</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'classifier': RandomForestClassifier(bootstra...</td>\n      <td>0.437848</td>\n      <td>0.457020</td>\n      <td>0.439155</td>\n      <td>0.447037</td>\n      <td>0.441467</td>\n      <td>0.444505</td>\n      <td>0.007003</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "#No depth limit no pca\n",
    "from sklearn.dummy import DummyClassifier\n",
    "filename = 'best_model_no_pruning.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "cv_results_df = pd.DataFrame(loaded_model.cv_results_)\n",
    "cv_results_df = cv_results_df.sort_values(by=['rank_test_score'])\n",
    "cv_results_df[\n",
    "    ['params', 'rank_test_score', 'mean_test_score', 'std_test_score']\n",
    "    ]\n",
    "#Check how well model generalizes\n",
    "y_train_pred = loaded_model.predict(X_train)\n",
    "train_ac = accuracy_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "#dummy classifier\n",
    "dummy_score_dict = {}\n",
    "strategies = ['stratified', 'most_frequent', 'uniform']\n",
    "for strategy in strategies:\n",
    "        dclf = DummyClassifier(strategy=strategy)\n",
    "        dclf.fit(X_train, y_train)\n",
    "        dummy_score = dclf.score(X_test, y_test)\n",
    "        dummy_score_dict[strategy] = dummy_score\n",
    "dummy_df = pd.DataFrame.from_dict(dummy_score_dict, orient='index', columns=['score'])\n",
    "\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "df_best_classifier = loaded_model.best_estimator_.get_params()['classifier']\n",
    "#,'best classifier': df_best_classifier\n",
    "results = pd.DataFrame({\"Train Accuracy\": train_ac, \"Test Accuracy\": ac, \"Train F1\":train_f1, \"Test F1\" : f1}, index=[key])\n",
    "print(\"Cross-Validation best parameters: \", cv_results_df.iloc[0]['param_classifier'])\n",
    "print(\"Cross-validation mean test score:\", cv_results_df.iloc[0]['mean_test_score'])\n",
    "dfresults = dfresults.append(results)\n",
    "print(dummy_df)\n",
    "print(dfresults)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cv_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   24.2s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   46.4s\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.7min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  7.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 15.3min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 21.6min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 31.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 32.7min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 44.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 56.8min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 75.7min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 93.1min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 139.5min\n",
      "[Parallel(n_jobs=-1)]: Done 220 out of 220 | elapsed: 153.8min finished\n"
     ]
    }
   ],
   "source": [
    "#with depth limit and no pca\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle\n",
    "\n",
    "\n",
    "dfdict = {'week':week}\n",
    "\n",
    "\n",
    "dfresults= pd.DataFrame()\n",
    "for key, df in dfdict.items():\n",
    "        X = df.drop('DraftPosition', axis=1)\n",
    "        y = df['DraftPosition']\n",
    "        #categorical_features = list(X.select_dtypes(include=['category', object]).columns)\n",
    "        #categorical_transformer = make_pipeline(OneHotEncoder(sparse=True, handle_unknown='ignore'))\n",
    "\n",
    "        numeric_features = list(X.select_dtypes(include=['int', 'float']).columns)\n",
    "        scalers_to_test = [StandardScaler(), MinMaxScaler()]\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='median')),\n",
    "                ('scaler', MinMaxScaler())\n",
    "        ])\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "                ('num', numeric_transformer, numeric_features)])\n",
    "                #('cat', categorical_transformer, categorical_features)])\n",
    "        pca = PCA()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('pca', pca),\n",
    "                                ('classifier', RandomForestClassifier())])\n",
    "        search_space = [{'classifier': [RandomForestClassifier()],\n",
    "                        'classifier__n_estimators': [64,96,128, 256],\n",
    "                        'classifier__max_depth': np.linspace(1,50,5),\n",
    "                        'classifier__criterion': ['gini', 'entropy']},\n",
    "                        {'classifier': [SVC()],\n",
    "                        'classifier__C': [0.25, 1],\n",
    "                        'classifier__kernel': ['poly', 'rbf']}]\n",
    "        \n",
    "        clf_CV = GridSearchCV(clf, search_space, cv=5, n_jobs=-1, verbose=10)\n",
    "        best_model = clf_CV.fit(X_train, y_train)\n",
    "        #saving model (https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/)\n",
    "        filename = 'best_model_pruned.sav'\n",
    "        pickle.dump(best_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cross-Validation best parameters:  RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='entropy', max_depth=13.25,\n",
      "                       max_features='auto', max_leaf_nodes=None,\n",
      "                       max_samples=None, min_impurity_decrease=0.0,\n",
      "                       min_impurity_split=None, min_samples_leaf=1,\n",
      "                       min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                       n_estimators=256, n_jobs=None, oob_score=False,\n",
      "                       random_state=None, verbose=0, warm_start=False)\n",
      "Cross-validation mean test score: 0.32714773850188134\n",
      "                  score\n",
      "stratified     0.130227\n",
      "most_frequent  0.204258\n",
      "uniform        0.108892\n",
      "      Train Accuracy  Test Accuracy  Train F1   Test F1\n",
      "week        0.642252       0.347542  0.650995  0.300821\n",
      "[[4077   52   30  121  317    8   31   15  136]\n",
      " [1044  383   21   91  365   10   41   33  155]\n",
      " [1105   27  199   74  301   27   42   19  103]\n",
      " [1566   85   34  642  499   15   47   36  113]\n",
      " [1638   67   24  176 1777   24   37   21  127]\n",
      " [ 556   34   31   83  230  117   18   19   59]\n",
      " [1297   84   33  105  388   15  212    4  100]\n",
      " [ 807   72   19   96  168   11   46   93   72]\n",
      " [1603   61   53  122  358    9   45   16  645]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          DB       0.30      0.85      0.44      4787\n",
      "          DE       0.44      0.18      0.25      2143\n",
      "          DT       0.45      0.10      0.17      1897\n",
      "          LB       0.43      0.21      0.28      3037\n",
      "          OL       0.40      0.46      0.43      3891\n",
      "          QB       0.50      0.10      0.17      1147\n",
      "          RB       0.41      0.09      0.15      2238\n",
      "          TE       0.36      0.07      0.11      1384\n",
      "          WR       0.43      0.22      0.29      2912\n",
      "\n",
      "    accuracy                           0.35     23436\n",
      "   macro avg       0.41      0.25      0.26     23436\n",
      "weighted avg       0.40      0.35      0.30     23436\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "27     296.309531      5.391066         0.877804        0.082429   \n",
       "26     148.728888      3.195423         0.544117        0.052281   \n",
       "25     110.084859      0.949237         0.340571        0.052484   \n",
       "24      75.484253      1.373811         0.230121        0.027460   \n",
       "7      119.171806      0.855958         1.006449        0.088094   \n",
       "\n",
       "                                     param_classifier  \\\n",
       "27  RandomForestClassifier(bootstrap=True, ccp_alp...   \n",
       "26  RandomForestClassifier(bootstrap=True, ccp_alp...   \n",
       "25  RandomForestClassifier(bootstrap=True, ccp_alp...   \n",
       "24  RandomForestClassifier(bootstrap=True, ccp_alp...   \n",
       "7   RandomForestClassifier(bootstrap=True, ccp_alp...   \n",
       "\n",
       "   param_classifier__criterion param_classifier__max_depth  \\\n",
       "27                     entropy                       13.25   \n",
       "26                     entropy                       13.25   \n",
       "25                     entropy                       13.25   \n",
       "24                     entropy                       13.25   \n",
       "7                         gini                       13.25   \n",
       "\n",
       "   param_classifier__n_estimators param_classifier__C  \\\n",
       "27                            256                 NaN   \n",
       "26                            128                 NaN   \n",
       "25                             96                 NaN   \n",
       "24                             64                 NaN   \n",
       "7                             256                 NaN   \n",
       "\n",
       "   param_classifier__kernel  \\\n",
       "27                      NaN   \n",
       "26                      NaN   \n",
       "25                      NaN   \n",
       "24                      NaN   \n",
       "7                       NaN   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "27  {'classifier': RandomForestClassifier(bootstra...           0.310602   \n",
       "26  {'classifier': RandomForestClassifier(bootstra...           0.309026   \n",
       "25  {'classifier': RandomForestClassifier(bootstra...           0.307975   \n",
       "24  {'classifier': RandomForestClassifier(bootstra...           0.305453   \n",
       "7   {'classifier': RandomForestClassifier(bootstra...           0.296312   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "27           0.324296           0.323665           0.335540   \n",
       "26           0.327133           0.318621           0.334910   \n",
       "25           0.321459           0.324926           0.332177   \n",
       "24           0.311896           0.318516           0.329025   \n",
       "7            0.313157           0.299391           0.316625   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "27           0.341635         0.327148        0.010718                1  \n",
       "26           0.342055         0.326349        0.011665                2  \n",
       "25           0.329340         0.323176        0.008439                3  \n",
       "24           0.348256         0.322629        0.014998                4  \n",
       "7            0.328289         0.310755        0.011708                5  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_classifier</th>\n      <th>param_classifier__criterion</th>\n      <th>param_classifier__max_depth</th>\n      <th>param_classifier__n_estimators</th>\n      <th>param_classifier__C</th>\n      <th>param_classifier__kernel</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>split4_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27</th>\n      <td>296.309531</td>\n      <td>5.391066</td>\n      <td>0.877804</td>\n      <td>0.082429</td>\n      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n      <td>entropy</td>\n      <td>13.25</td>\n      <td>256</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'classifier': RandomForestClassifier(bootstra...</td>\n      <td>0.310602</td>\n      <td>0.324296</td>\n      <td>0.323665</td>\n      <td>0.335540</td>\n      <td>0.341635</td>\n      <td>0.327148</td>\n      <td>0.010718</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>148.728888</td>\n      <td>3.195423</td>\n      <td>0.544117</td>\n      <td>0.052281</td>\n      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n      <td>entropy</td>\n      <td>13.25</td>\n      <td>128</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'classifier': RandomForestClassifier(bootstra...</td>\n      <td>0.309026</td>\n      <td>0.327133</td>\n      <td>0.318621</td>\n      <td>0.334910</td>\n      <td>0.342055</td>\n      <td>0.326349</td>\n      <td>0.011665</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>110.084859</td>\n      <td>0.949237</td>\n      <td>0.340571</td>\n      <td>0.052484</td>\n      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n      <td>entropy</td>\n      <td>13.25</td>\n      <td>96</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'classifier': RandomForestClassifier(bootstra...</td>\n      <td>0.307975</td>\n      <td>0.321459</td>\n      <td>0.324926</td>\n      <td>0.332177</td>\n      <td>0.329340</td>\n      <td>0.323176</td>\n      <td>0.008439</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>75.484253</td>\n      <td>1.373811</td>\n      <td>0.230121</td>\n      <td>0.027460</td>\n      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n      <td>entropy</td>\n      <td>13.25</td>\n      <td>64</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'classifier': RandomForestClassifier(bootstra...</td>\n      <td>0.305453</td>\n      <td>0.311896</td>\n      <td>0.318516</td>\n      <td>0.329025</td>\n      <td>0.348256</td>\n      <td>0.322629</td>\n      <td>0.014998</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>119.171806</td>\n      <td>0.855958</td>\n      <td>1.006449</td>\n      <td>0.088094</td>\n      <td>RandomForestClassifier(bootstrap=True, ccp_alp...</td>\n      <td>gini</td>\n      <td>13.25</td>\n      <td>256</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>{'classifier': RandomForestClassifier(bootstra...</td>\n      <td>0.296312</td>\n      <td>0.313157</td>\n      <td>0.299391</td>\n      <td>0.316625</td>\n      <td>0.328289</td>\n      <td>0.310755</td>\n      <td>0.011708</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "#with depth limit and no pca\n",
    "filename = 'best_model_pruned.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "cv_results_df = pd.DataFrame(loaded_model.cv_results_)\n",
    "cv_results_df = cv_results_df.sort_values(by=['rank_test_score'])\n",
    "cv_results_df[\n",
    "    ['params', 'rank_test_score', 'mean_test_score', 'std_test_score']\n",
    "    ]\n",
    "#Check how well model generalizes\n",
    "y_train_pred = loaded_model.predict(X_train)\n",
    "train_ac = accuracy_score(y_train, y_train_pred)\n",
    "train_f1 = f1_score(y_train, y_train_pred, average='weighted')\n",
    "\n",
    "#dummy classifier\n",
    "dummy_score_dict = {}\n",
    "strategies = ['stratified', 'most_frequent', 'uniform']\n",
    "for strategy in strategies:\n",
    "        dclf = DummyClassifier(strategy=strategy)\n",
    "        dclf.fit(X_train, y_train)\n",
    "        dummy_score = dclf.score(X_test, y_test)\n",
    "        dummy_score_dict[strategy] = dummy_score\n",
    "dummy_df = pd.DataFrame.from_dict(dummy_score_dict, orient='index', columns=['score'])\n",
    "\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "#cm = confusion_matrix(y_test, y_pred)\n",
    "df_best_classifier = loaded_model.best_estimator_.get_params()['classifier']\n",
    "#,'best classifier': df_best_classifier\n",
    "results = pd.DataFrame({\"Train Accuracy\": train_ac, \"Test Accuracy\": ac, \"Train F1\":train_f1, \"Test F1\" : f1}, index=[key])\n",
    "print(\"Cross-Validation best parameters: \", cv_results_df.iloc[0]['param_classifier'])\n",
    "print(\"Cross-validation mean test score:\", cv_results_df.iloc[0]['mean_test_score'])\n",
    "dfresults = dfresults.append(results)\n",
    "print(dummy_df)\n",
    "print(dfresults)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "cv_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}