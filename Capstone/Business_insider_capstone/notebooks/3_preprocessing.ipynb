{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Preprocessing Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "In this notebook, we will be preprocessing the data for running them through our models.  This includes standardizing the scale of the data, and dealing with the imbalanced classes in the dataset.  There are no categorical variables, so there is no encoding needed before using any model.  For the imbalanced classes, we will be using the Synthetic Minority Oversampling TEchnique (SMOTE)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/nooutlier_EDA.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(4909, 95)"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "source": [
    "There are a lot of features that do not look to have a normal distribution, so we will use a standard scaler to remove the mean and scale to unit variance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 6.34445434e+00, -2.85284146e+00, -2.80904766e+00, ...,\n",
       "        -2.24001963e-01, -5.13182376e-01, -9.99716462e-01],\n",
       "       [ 6.34445434e+00, -8.74521323e-01, -4.68848059e-01, ...,\n",
       "        -1.11848780e+00,  3.79744151e+00, -2.38660582e-01],\n",
       "       [-1.57617968e-01, -2.42694601e+00, -2.37165854e+00, ...,\n",
       "        -2.13518808e-01, -4.57277470e-01, -1.03195148e+00],\n",
       "       ...,\n",
       "       [-1.57617968e-01, -2.73978090e-01, -4.47593856e-01, ...,\n",
       "         3.17384962e-04,  2.85509237e-01, -4.62720982e-01],\n",
       "       [-1.57617968e-01, -6.62084261e-01, -4.72203986e-01, ...,\n",
       "        -2.66279459e-02,  2.20286332e-01, -1.26891909e-01],\n",
       "       [-1.57617968e-01, -7.13150863e-01, -5.65051293e-01, ...,\n",
       "        -1.31820904e-01, -1.00146484e-01,  2.24832621e+00]])"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Bankrupt?', axis=1)\n",
    "y = df['Bankrupt?']"
   ]
  },
  {
   "source": [
    "## Summarize Current Class instances"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    4790\n",
       "1     119\n",
       "Name: Bankrupt?, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "source": [
    "There are 4790 companies that did not go bankrupt, and 119 that unfortunately did"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Oversample the minority class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X_smote, y_smote = oversample.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    4790\n",
       "1    4790\n",
       "Name: Bankrupt?, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "y_smote.value_counts()"
   ]
  },
  {
   "source": [
    "# Create train test split for unbalanced and balanced classes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_smote, y_smote, test_size=.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}